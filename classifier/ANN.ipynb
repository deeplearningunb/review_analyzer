{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Too few films take on the art of arguing as a ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The film leaves a tremendous impact.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>From 1957 and first-time director Sidney Lumet...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mechanically written, but within its own middl...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>A strangely realistic thriller.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  Review\n",
       "0  Too few films take on the art of arguing as a ...       1\n",
       "1               The film leaves a tremendous impact.       1\n",
       "3  From 1957 and first-time director Sidney Lumet...       1\n",
       "4  Mechanically written, but within its own middl...       1\n",
       "5                    A strangely realistic thriller.       1"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Part 1 - Data Preprocessing\n",
    "\n",
    "# Importing the libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# # Importing the dataset\n",
    "# dataset = pd.read_csv('movies_merged.csv', sep='|')\n",
    "# # Remove NaN\n",
    "# dataset = dataset.dropna()\n",
    "# # Lower all words\n",
    "# dataset = dataset.applymap(str.lower)\n",
    "\n",
    "def read_csv(name, index_col=None):\n",
    "    df = pd.read_csv(name, low_memory=False, sep='|', index_col=index_col)\n",
    "    return df\n",
    "\n",
    "def process_df(name):\n",
    "    dataset = read_csv(name)\n",
    "    dataset.dropna(inplace=True)\n",
    "    dataset['Review'].replace(to_replace='Fresh', value=1, inplace=True)\n",
    "    dataset['Review'].replace(to_replace='Rotten', value=0, inplace=True)\n",
    "    return dataset\n",
    "\n",
    "dataset = process_df('movies_merged.csv')\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Importing the Keras libraries and packages\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing import sequence\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer(\n",
    "    analyzer = 'word',\n",
    "    lowercase = False,\n",
    ")\n",
    "features = vectorizer.fit_transform(\n",
    "    dataset.iloc[:,0]\n",
    ")\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# X_train, X_test, y_train, y_test  = train_test_split(\n",
    "#         features, \n",
    "#         dataset.iloc[:,1],\n",
    "#         train_size=0.80, \n",
    "#         random_state=1234)\n",
    "\n",
    "MAX_WORDS = 1000\n",
    "MAX_LEN = 150\n",
    "\n",
    "\n",
    "def get_X_from_df(df):\n",
    "    X = df.Text\n",
    "    return X\n",
    "\n",
    "def get_Y_from_df(df):\n",
    "    Y = df.Review\n",
    "    #le = LabelEncoder()\n",
    "    #Y = le.fit_transform(Y)\n",
    "    #Y = Y.reshape(-1,1)\n",
    "    return Y\n",
    "\n",
    "def get_sequence_matrix_from_X(X, tok):\n",
    "    tok.fit_on_texts(X)\n",
    "    sequences = tok.texts_to_sequences(X)\n",
    "    sequences_matrix = sequence.pad_sequences(sequences, maxlen=MAX_LEN)\n",
    "    return sequences_matrix\n",
    "\n",
    "\n",
    "sar_acc = process_df('movies_merged.csv')\n",
    "X = get_X_from_df(sar_acc)\n",
    "Y = get_Y_from_df(sar_acc)\n",
    "TEST_SIZE = 0.2\n",
    "RANDOM_STATE = 42\n",
    "X_train,X_test,Y_train,Y_test = train_test_split(X, Y, test_size=TEST_SIZE, random_state=RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/cjjcastro/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/cjjcastro/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 44645 samples, validate on 4961 samples\n",
      "Epoch 1/100\n",
      "44645/44645 [==============================] - 5s 107us/step - loss: 0.2725 - acc: 0.9310 - val_loss: 0.2531 - val_acc: 0.9339\n",
      "Epoch 2/100\n",
      "44645/44645 [==============================] - 4s 94us/step - loss: 0.2548 - acc: 0.9311 - val_loss: 0.2472 - val_acc: 0.9339\n",
      "Epoch 3/100\n",
      "44645/44645 [==============================] - 5s 111us/step - loss: 0.2520 - acc: 0.9311 - val_loss: 0.2461 - val_acc: 0.9339\n",
      "Epoch 4/100\n",
      "44645/44645 [==============================] - 6s 123us/step - loss: 0.2511 - acc: 0.9311 - val_loss: 0.2446 - val_acc: 0.9339\n",
      "Epoch 5/100\n",
      "44645/44645 [==============================] - 6s 126us/step - loss: 0.2508 - acc: 0.9311 - val_loss: 0.2443 - val_acc: 0.9339\n",
      "Epoch 6/100\n",
      "44645/44645 [==============================] - 6s 141us/step - loss: 0.2507 - acc: 0.9311 - val_loss: 0.2436 - val_acc: 0.9339\n",
      "Epoch 7/100\n",
      "44645/44645 [==============================] - 6s 135us/step - loss: 0.2503 - acc: 0.9311 - val_loss: 0.2441 - val_acc: 0.9339\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f233951e4a8>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Part 2 - Now let's make the ANN!\n",
    "\n",
    "\n",
    "def ANN():\n",
    "    # Initialising the ANN\n",
    "    classifier = Sequential()\n",
    "\n",
    "    # Adding the input layer and the first hidden layer\n",
    "    classifier.add(Dense(units = 6, kernel_initializer = 'uniform', activation = 'relu', input_dim = (150)))\n",
    "    # classifier.add(Dropout(rate = 0.1))\n",
    "\n",
    "    # Adding the second hidden layer\n",
    "    classifier.add(Dense(units = 6, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "    # classifier.add(Dropout(rate = 0.1))\n",
    "\n",
    "    # Adding the output layer\n",
    "    classifier.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid'))\n",
    "\n",
    "    # Compiling the ANN\n",
    "    classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "    # Fitting the ANN to the Training set\n",
    "#     classifier.fit(X_train, y_train, batch_size = 10, epochs = 100)\n",
    "    return classifier\n",
    "\n",
    "model = ANN()\n",
    "model.sumary()\n",
    "tok = Tokenizer(num_words=MAX_WORDS)\n",
    "X_train_sequences = get_sequence_matrix_from_X(X_train, tok)\n",
    "model.fit(X_train_sequences,\n",
    "          Y_train,batch_size=10,\n",
    "          epochs=100,\n",
    "          validation_split=0.1,\n",
    "          callbacks=[EarlyStopping(monitor='val_loss',min_delta=0.0001)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
