# Review Analyzer
O Review Analyzer √© um projeto open source com o objetivo de analisar reviews. 

Utilizamos o Kibana como interface de visualiza√ß√£o, para guardar os dados usamos o Elasticsearch que √© um servidor de buscas distribu√≠do e o Logstash para fazer o processamento dos dados.

Para treinar os nossos modelos usamos as bilbioteca do Tensorflow e a do Scikit Learn.

Fique a vontade para contribuir para o reposit√≥rio com mais exemplos seja de dados ou de modelos.

## Tecnologias

<img src="https://www.tensorflow.org/images/tf_logo_social.png" alt="Tensorflow" height="100" width="200"/><img src="https://s3.amazonaws.com/keras.io/img/keras-logo-2018-large-1200.png" alt="Keras" height="100" width="250"/><img src="https://www.python.org/static/opengraph-icon-200x200.png" alt="Python" height="100" width="110"/><img src="https://i0.wp.com/kubedex.com/wp-content/uploads/2018/09/kibana-1.png" alt="Kibana" height="100" width="110"/><img src="https://miro.medium.com/max/892/1*AYP0Mg_MwJMm3Kbx8Xa8lQ.png" alt="ElasticSearch" height="100" width="200"/><img src="https://upload.wikimedia.org/wikipedia/commons/thumb/0/05/Scikit_learn_logo_small.svg/1200px-Scikit_learn_logo_small.svg.png" alt="Scikit" height="100" width="200"/><img src="https://www.mundodocker.com.br/wp-content/uploads/2015/06/docker_facebook_share.png" alt="Docker" height="100" width="110"/><img src="https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcQnoLkQi88nL9hJV0iDIJKPl9PEqembr1XCpg___eMmEF1tiNF4" alt="Github" height="100" width="110"/>
## Utiliza√ß√£o

### Utilizando Online
Atualmente n√£o temos um servidor com o nosso ambiente.

### Instalando Localmente
Primeiramente √© necess√°rio ter [Docker](https://docs.docker.com/install/) e o [Docker-Compose](https://docs.docker.com/compose/install/). Com eles √© poss√≠vel subir a parte de visualiza√ß√£o dos dados.

Para o Web Scrapping e subir os dados no kibana pelo Elasticsearch, instale as depend√™ncias que se encontram no `requirements.txt`.

Recomendamos que instale isso tudo dentro uma virtualenv ou fa√ßa um container voc√™ decide. Neste exemplo vamos instalar tudo dentro de uma virtualenv. Come√ßando desde instalar uma virtualenv.

```bash
pip install virtualenv
virtualenv review_analyzer
```
Agora temos uma virtualenv falta agora s√≥ falta ativar ela e instalar os requirements.txt nela.

```bash
source /caminho/para/review_analyzer/bin/activate
pip install -r requirements.txt 
```

E instalando os `requirements.txt` voc√™ tamb√©m consegue rodar nossos exemplos de classificadores :)

### Rodando o Ambiente

Para baixar 

```bash
cd ~/your/directory/
git clone https://github.com/deeplearningunb/review_analyzer.git
cd review_analyzer
```

Para subir os containers do Docker

```bash
docker-compose build
docker-compose up
```

Se tudo deu certo, j√° √© poss√≠vel utilizar o Kibana entrando no endere√ßo `http://localhost:5601/`. Entrando nele, voc√™ ver√° a interface do Kibana. Acessando `http://localhost:9200/`, voc√™ ter√° acesso ao Elasticsearch.

Para ter acesso aos nosso jupyter notebooks √© necess√°rio que voc√™ inicie o jupyter ou o jupyter-lab ele tem modo dark para programar de madrugada :D.

Para o lab
```bash
jupyter lab
```
Para vers√£o normal
```bash
jupyter-notebook
```
E ap√≥s entre em `http://localhost:8888/` e pode come√ßar a olhar nossos exemplos.

### Rodando nossas ferramentas

#### Web Scrapping
Para facilitar a analise de sentimento, n√≥s desenvolvemos algumas fun√ß√µes:

O Web Scrapping de reviews de filmes foi criado usando as bibliotecas do Beautiful Soup e do request atualmente ela s√≥ suporta o `https://www.rottentomatoes.com/`. 

Para utilizar √© necess√°rio criar um arquivo de urls.

```bash
cd web_scrapping
touch nome_do_arquivo_de_urls
vim nome_do_arquivo_de_urls
```

Dentro do arquivo escreva o nome das urls que voc√™ quer que seja feito a extra√ß√£o das reviews. Como no exemplo abaixo

```
https://www.rottentomatoes.com/m/black_panther_2018
https://www.rottentomatoes.com/m/mission_impossible_fallout
https://www.rottentomatoes.com/m/blackkklansman
https://www.rottentomatoes.com/m/spider_man_into_the_spider_verse
https://www.rottentomatoes.com/m/roma_2018
```

Depois disso basta passar o arquivo como par√¢metro.
```bash
cd web_scrapping
python3 get_review.py nome_do_arquivo_de_urls
```

#### Comunica√ß√£o Elasticsearch

Para importar os arquivos csv, √© necess√°rio fazer v√°rias requisi√ß√µes. Para agilizar esse processo, n√≥s criamos uma fun√ß√£o que faz isso para voc√™. S√≥ precisa passar os par√¢metros e ela far√° o resto.

```bash
cd import_to_kibana
python3 import_csv.py nome_do_arquivo_csv index tipo_doc
```
#### TF-IDF

Analisar os dados √© um parte importante no processo de treinar os modelo para isso fizemos um tf‚Äìidf (abrevia√ß√£o do ingl√™s term frequency‚Äìinverse document frequency, que significa frequ√™ncia do termo‚Äìinverso da frequ√™ncia nos documentos) que √© uma medida estat√≠stica que tem o intuito de indicar a import√¢ncia de uma palavra dentro de uma review.

A sua utiliza√ß√£o √© feita conforme o exemplo abaixo 

```bash
cd exploratory_data_analysis
python3 tfidf.py nome_do_arquivo_csv
```

Ele ir√° retornar as palavras e o seu valor para os Fresh e os Rotten.

## Contribuidores

Agradecimentos para essas pessoas maravilhosas ([emoji key](https://allcontributors.org/docs/en/emoji-key)):
<!-- ALL-CONTRIBUTORS-LIST:START - Do not remove or modify this section -->
<!-- prettier-ignore -->
<table>
    <tr>
        <td align="center">
            <a href="https://github.com/cjjcastro"><img src="https://avatars0.githubusercontent.com/u/26393787?v=4" width="100px;" alt="Cleber J√∫nior" />
                <br /><sub><b>Cleber J√∫nior</b></sub></a>
            <br /><a href="https://github.com/deeplearningunb/review_analyzer/commits?author=cjjcastro" title="Code">üíª</a></td>
        <td align="center">
            <a href="https://github.com/Hiroshi18"><img src="https://avatars0.githubusercontent.com/u/26282955?v=4" width="100px;" alt="Lucas Hiroshi Horinouchi" />
                <br /><sub><b>Lucas Hiroshi Horinouchi</b></sub></a>
            <br /><a href="https://github.com/deeplearningunb/review_analyzer/commits?author=Hiroshi18" title="Code">üíª</a> <a href="https://github.com/deeplearningunb/review_analyzer/commits?author=Hiroshi18" title="Documentation">üìñ</a></td>
        <td align="center">
            <a href="https://github.com/mateusnr"><img src="https://avatars0.githubusercontent.com/u/13491922?v=4" width="100px;" alt="Mateus N√≥brega" />
                <br /><sub><b>Mateus N√≥brega</b></sub></a>
            <br /><a href="https://github.com/deeplearningunb/review_analyzer/commits?author=mateusnr" title="Code">üíª</a></td>
        <td align="center">
            <a href="https://github.com/Lorryaze"><img src="https://avatars1.githubusercontent.com/u/30262806?v=4" width="100px;" alt="Francisco Heronildo" />
                <br /><sub><b>Lorrany Azevedo</b></sub></a>
            <br /><a href="https://github.com/deeplearningunb/review_analyzer/commits?author=Lorryaze" title="Code">üíª</a></td>
    </tr>
</table>

<!-- ALL-CONTRIBUTORS-LIST:END -->

## License

O nosso c√≥digo e as ferramentas desenvolvidas pela equipe est√° dentro da [MIT License](./LICENSE), mas as ferramentas externas como o Kibana e o Elastic Search s√£o Apache.
